---
title: "Project Data"
author: "Jed Green"
date: "2024-01-18"
output:
  word_document: default
  pdf_document: default
---

This my attempt at an R Markdown script. I hope this will make the data more reproducible.

Below is a list of all the packages I used:

```{r}
library(haven)
library(gmodels)
library(rcompanion)
library(chisq.posthoc.test)
library(stargazer)
library(ggplot2)
library(tidyverse)
library(xtable)
library(AICcmodavg)
library(rmarkdown)
library(tinytex)
library(reshape2)
```

As all of our data comes from the longitudinal C19PRC_Uk survey our first step is to merge all of the waves together. The first step is to read in all the different .sav files containing all of the data from the different waves. We did this using "read_sav" from the package Haven as R cannot naturally read in .sav files. The second step was to extract only the variables that are necessary as the data set would be too large if we merged everything. The two variables from each subsequent data set that We selected was "PID" and the "Wave type". This is because the "PID" variable allows us to merge the data based on individuals as each respondent has a unique "PID". In addition we needed the "Wave type" variable from each wave in order to identify who was a recontact and who was a respondent. Finally we merged the data by the "PID" variable in order to get all of our Data into one data set.

```{r}
### Step 1: Reading in all databases:

df<-read_sav("C19PRC_UKW1W2_archive_final.sav")
df1<-read_sav("C19PRC_UK_W3_archive_final.sav")
df2<-read_sav("C19PRC_UK_W4_archive_final.sav")
df3<-read_sav("C19PRC_UKW5_archive_final.sav")
df4<-read_sav("C19PRC_UK_W6_archive_final.sav")

### Step 2: Making the databases contain only variables needed:

ldf1<-as.data.frame(cbind(df1$pid,df1$W3_Type))
colnames(ldf1)<-c("pid","W3_Type")

ldf2<-as.data.frame(cbind(df2$pid,df2$W4_Type))
colnames(ldf2)<-c("pid","W4_Type")

ldf3<-as.data.frame(cbind(df3$pid,df3$W5_Type))
colnames(ldf3)<-c("pid","W5_Type")

ldf4<-as.data.frame(cbind(df4$pid,df4$W6_Type))
colnames(ldf4)<-c("pid","W6_Type")


### Step 3: Merging data sets:

mdf1<-merge.data.frame(df,ldf1, by ="pid", all = T)
mdf2<-merge.data.frame(mdf1,ldf2, by ="pid", all = T)
mdf3<-merge.data.frame(mdf2,ldf3, by ="pid", all = T)
mdf4<-merge.data.frame(mdf3,ldf4, by ="pid", all = T)
```

The next step now that we have merged all of our data together is insert values for the missing data. As both the "Present" and "Wave Type" variable are unique to each wave to creates a lot NA's when we merge them together.  Therefore, we replaced all the NA's with -99 values. This allows for them to be represented in our analysis.

```{r}
mdf4$W1_Present[is.na(mdf4$W1_Present)]<--99
mdf4$W2_Present[is.na(mdf4$W2_Present)]<--99
mdf4$W3_Type[is.na(mdf4$W3_Type)]<--99
mdf4$W4_Type[is.na(mdf4$W4_Type)]<--99
mdf4$W5_Type[is.na(mdf4$W5_Type)]<--99
mdf4$W6_Type[is.na(mdf4$W6_Type)]<--99
```

Now we have edited our data we need to tidy and clean it. First lets create a new variable that separates the PHQ-9 variable into the different depression severity levels. This will go on to form our dependent variable.

```{r}
### creating Depression severity variable

mdf4$W1_Dep_Severity <- NA
mdf4$W1_Dep_Severity[mdf4$W1_Depression_Total >= 0 &mdf4$W1_Depression_Total <= 4 ] <- "None minimal"
mdf4$W1_Dep_Severity[mdf4$W1_Depression_Total >= 5 & mdf4$W1_Depression_Total <= 9 ] <- "Mild"
mdf4$W1_Dep_Severity[mdf4$W1_Depression_Total >= 10 & mdf4$W1_Depression_Total <= 14] <- "Moderate"
mdf4$W1_Dep_Severity[mdf4$W1_Depression_Total >= 15 & mdf4$W1_Depression_Total <= 19] <- "Moderately Severe"
mdf4$W1_Dep_Severity[mdf4$W1_Depression_Total >= 20 & mdf4$W1_Depression_Total <= 27] <- "Severe"
```

Next lets create some variables to identify how many people attended each wave consecutively. In order to do this we used the wave type and present variable for each wave. For the first two waves there were no top-up respondents and therefore we can use the W1_present and W2_present variables in order to calculate the number of people who were present in wave 1 and then attend wave 2. For subsequent waves it gets more complex as top ups are introduced. Therefore from wave 3 onwards we use each individual wave type variable to identify if they are a recontact or a top up respondent. For all waves (except wave 3) if the Wave type variable is = 1 then it means that they were a recontact (for wave 3 if they were a recontact wave3 type = 0). 

```{r}
### Re-coding variable: answering waves one after another in order:
mdf4$presentwave1<- ifelse(mdf4$W1_Present == 1,1,0)
mdf4$presentwave1_2 <- ifelse(mdf4$W1_Present == 1 & mdf4$W2_Present == 1,1,0)
mdf4$presentwave1_2_3 <-ifelse(mdf4$W1_Present == 1 & mdf4$W2_Present == 1 & mdf4$W3_Type == 0,1,0)
mdf4$presentwave1_2_3_4<-ifelse(mdf4$W1_Present == 1 & mdf4$W2_Present == 1 & mdf4$W3_Type == 0 & mdf4$W4_Type == 1,1,0)
mdf4$presentwave1_2_3_4_5<-ifelse(mdf4$W1_Present == 1 & mdf4$W2_Present == 1 & mdf4$W3_Type == 0 & mdf4$W4_Type == 1 & mdf4$W5_Type == 1,1,0)
mdf4$presentwave1_2_3_4_5_6<-ifelse(mdf4$W1_Present == 1 & mdf4$W2_Present == 1 & mdf4$W3_Type == 0 & mdf4$W4_Type 
                                    == 1 & mdf4$W5_Type == 1 & mdf4$W6_Type == 1,1,0)
```

Now we have created these new variables we can now create tables out them. The sum of each table is equal to the total number of contacts across all six waves (both Top-Ups and Recontacts) which is 5364. The results under 0 in each table equal to the total number of Top-Ups and those who drop out at each stage of the survey process. The results under 1 in each table is the total number of people who completed each wave up until and including the last one listed. Therefore, if we were to subtract the total number of Top-Up contacts (3339) from the 0 value in each table we would be left with the number of drop outs between each wave - and this is what we find. 

```{r}
### Printing each variable in a table
table(mdf4$presentwave1)
table(mdf4$presentwave1_2)
table(mdf4$presentwave1_2_3)
table(mdf4$presentwave1_2_3_4)
table(mdf4$presentwave1_2_3_4_5)
table(mdf4$presentwave1_2_3_4_5_6)
```

Now we can input the values generated from this filtering into its own matrix. We did this by running each variable and inputting each of the successful test cases (ie. output = 1) into a matrix. This matrix was then converted into a data frame. This data frame represents the number of people who attended each wave without missing one. 

```{r}
Waves_attended_consecutively <- matrix(c(2025,1406, 950, 771, 677, 582), ncol=1, byrow=TRUE)
rownames(Waves_attended_consecutively) <- c('Wave 1','Wave 2','Wave 3','Wave 4','Wave 5','Wave 6')
colnames(Waves_attended_consecutively) <- c('Present')
Waves_attended_consecutivelydf<-as.data.frame(Waves_attended_consecutively)
Waves_attended_consecutivelydf$Waves <- rownames(Waves_attended_consecutivelydf)
```

Now that we have made collated and cleaned our data we can now create some initial descriptive statistics. Lets first explore the distribution of depression amount wave 1 respondents. Below we have two graphs, both use the PHQ-9 variable. The first is a scale 1-27 the second is the distribution split into the different severity levels.

```{r}
# Graph 1: Depression PHQ-9 scale

hist(df$W1_Depression_Total,
     breaks = 30,
     xlim = c(0,30),
     ylim = c(0,800),
     xlab = "PHQ-9 Total Test Score",
     main = "Histogram of PHQ-9 Total Test Score")
```

```{r}
#Graph 2: Depression severity 

table(mdf4$W1_Dep_Severity)
data <- c(378, 227, 154, 1199, 67)
categories <- c("Mild", "Moderate", "Moderately Severe", "None minimal", "Severe")

# Create a data frame
BP1 <- data.frame(Category = categories, Count = data)

# Sort the data frame by Count in descending order
BP1 <- BP1[order(-BP1$Count), ]

# Create the bar plot
barplot(BP1$Count, names.arg = BP1$Category, main = "Bar Plot with Descending Bars",
        xlab = "Level of severity", ylab = "Frequency")
```

Graph 3 below shows the attrition rate of between waves. Reminder that this represents those who did not complete the waves in order

```{r}
### Graph 3: Attrition between waves:

ggplot(Waves_attended_consecutivelydf, aes(x = Waves, y = Present, group = 1)) +
  geom_line(color = "blue") +
  geom_point(color = "blue", size = 3) +
  labs(title = "Frequency by Waves", x = "Waves", y = "Present") +
  theme_minimal() +
  ylim(c(0,2100))

```

Our next step now that we have conducted some initial descriptive statistics is to compare the attrition rate between the different levels of depression severity. In order to do that we need to calculate the figures. We did this by creating tables showing the respondents who were were present at each wave (and present at all subsequent waves) and their wave 1 depression severity level. For each of the tables below values under the "0" Row represent all those who had dropped out/missed a survey. All values under the "1" row represent all respondents who have completed every survey up to and including the last number listed in the variable. This allows us to see all those who completed all surveys and their given depression severity. Finally the tables also have total columns so that we ensure that "0" and "1" rows add up to the total number contacts at wave one (2025) as this is the baseline from which we are measuring attrition. 

```{r}
### Depression and wave attrition tables
addmargins(table(mdf4$presentwave1, mdf4$W1_Dep_Severity),2)
addmargins(table(mdf4$presentwave1_2, mdf4$W1_Dep_Severity),2)
addmargins(table(mdf4$presentwave1_2_3, mdf4$W1_Dep_Severity),2)
addmargins(table(mdf4$presentwave1_2_3_4, mdf4$W1_Dep_Severity),2)
addmargins(table(mdf4$presentwave1_2_3_4_5,mdf4$W1_Dep_Severity),2)
addmargins(table(mdf4$presentwave1_2_3_4_5_6,mdf4$W1_Dep_Severity),2)
```

As we have calculated all those present at each wave and their depression severity level we can put this information into a data frame so that we can plot it. The figures for each row (as discussed above) are just the figures in the "1" Row i.e have completed every survey up to and including the last number listed in the variable. 

```{r}
### Creating the data frame from the table

wave_data <- data.frame(
  Severity = c("None minimal (0-4)", "Mild (5-9)", "Moderate (10-14)", "Moderately Severe (15-19)", "Severe (20-27)"),
  Wave_1 = c(1199,  378, 227, 154, 67),
  Wave_2 = c(896 , 243, 138, 95, 34),
  Wave_3 = c(637, 163, 78, 59, 13),
  Wave_4 = c(536, 124, 55, 47, 9),
  Wave_5 = c(474, 107, 51, 37, 8),
  Wave_6 = c(414, 91, 41, 28, 8))
```

With the Data frame created above we can now plot this information. In order to do this we used the ggplot2 and the tidyr package. Our First step was to us the pivot_longer() command which takes our original wide-format data frame wave_data and converts it into a long-format data frame called wave_data_long, where the wave numbers are stacked in a single column named Wave_Number, and the corresponding frequencies are stacked in another column named Frequency. This transformation allows us to then plot this new data frame. 

```{r}
### Converting into a long-format data frame:

wave_data_long <- pivot_longer(wave_data, cols = -Severity, names_to = "Wave_Number", values_to = "Frequency")
```

Next we created some values in order to help organise our visualisation code. These where just the colors of each level of depression and the order of the legend. 

```{r}
custom_colors <- c("None minimal (0-4)" = "darkgreen", "Mild (5-9)"= "lightgreen","Moderate (10-14)" = "orange",
                   "Moderately Severe (15-19)" = "red", "Severe (20-27)" = "darkred")
legend_order <- c("None minimal (0-4)", "Mild (5-9)", "Moderate (10-14)", "Moderately Severe (15-19)", "Severe (20-27)")
```

Below is the code used to create our first results graph. It has the frequency plotted on the Y axis and the number of waves attended in order on the X axis. It is then grouped by Wave 1 depression severity. 

```{r}
### Plotting the line graph for Frequencies:

ggplot(wave_data_long, aes(x = Wave_Number, y = Frequency, color = Severity, group = Severity)) +
  geom_line() +
  scale_color_manual(values = custom_colors, breaks = legend_order) +  # Assigning custom colors
  labs(title = "Frequency of Depression Severity Levels Across Waves",
       x = "Waves attended in order", y = "Frequency") +
  theme_minimal()
```

Whilst the graph above is great it might be better to visualise our data reactivate to wave 1. Therefore we need to mutate the frequency column in order to turn it into a percentage. 

```{r}
### Calculating percentages relative to Wave 1 for each severity level:

wave_data_long <- wave_data_long %>%
  group_by(Severity) %>%
  mutate(Percentage = Frequency / Frequency[Wave_Number == "Wave_1"] * 100)
```

Now we can re-plot the data but this time have percentage instead of frequency represented on the Y axis. 

```{r}
###Plotting the line graph with percentages relative to Wave 1 on the y-axis:

ggplot(wave_data_long, aes(x = Wave_Number, y = Percentage, color = Severity, group = Severity)) +
  geom_line() +
  scale_color_manual(values = custom_colors, breaks = legend_order) +  # Assigning custom colors and order
  labs(title = "Percentage of Depression Severity Levels and those who answered consecutive waves 
       Relative to Wave 1",
       x = "Wave Number", y = "Percentage") +
  theme_minimal() +
  ylim(0,100)
```

Finally Lets run a few tests for significance:  below is the code for an anvoa test using the data from our long-format data frame in order to test for significance. After this we run a Tukey Post-Hoc test in order to compare the means of every treatment to the means of every other treatment.

```{r}
### ANOVA of above data

two.way<-aov(wave_data_long$Percentage~wave_data_long$Severity+ wave_data_long$Wave_Number)
summary(two.way)

TukeyHSD(two.way)
```

We can also run a simple OlS regression. In order to do this we first need to convert our data frame from a wide format to a long format so that it is conducive to our regression. The wide format of our data is not conducive to regression analysis because each observation (or row) should represent a unique combination of the predictor variables. Once we have done that we also need to convert our depression severity measure from a character variable to a numeric one so that it too is conducive to regression analysis. Finally we run our regression with the counts of respondents at each wave as our dependent and an interaction term between the wave number level of depression severity. 

```{r}
# Reshape the data to long format

data_long <- melt(wave_data, id.vars = "Severity", variable.name = "Wave", value.name = "Counts")

# Convert Severity to numeric
severity_mapping <- c('None minimal (0-4)' = 1, 'Mild (5-9)' = 2, 'Moderate (10-14)' = 3, 'Moderately Severe (15-19)' = 4, 'Severe (20-27)' = 5)
data_long$Severity_Num <- as.numeric(factor(data_long$Severity, levels = names(severity_mapping)))



# Perform OLS regression
model <- lm(Counts ~ Wave * Severity_Num, data = data_long)

# Print the summary of the regression model
summary(model)
```

Interpretation of Coefficients:

Intercept: The intercept of 1151.40 represents the estimated count of attendees when the severity level is at its minimum (0-4) and the wave number is 1.
Severity_Num: The coefficient of -248.80 for Severity_Num suggests that, on average, for each unit increase in the severity level (measured in the numeric scale), the count of attendees decreases by 248.80, holding the wave constant.
Wave Coefficients: The coefficients for each wave indicate the change in the count of attendees compared to the reference wave (Wave 1).
Interaction Terms: The coefficients for the interaction terms represent how the effect of severity level changes across different waves. None of the interaction terms appear to be statistically significant at conventional levels.


Now we have explored the attrition rate in terms of Number of waves attended in order it may also be beneficial to explore the same relationship but instead this time using the total number of waves attended by each respondent. This is because respondents may skip a given wave but then rejoin (I.e a respondent may complete wave 1 skip wave 2 and 3 but renter and complete wave 4). Below is how we create the variable for this:

```{r}
mdf4$Waves_attended<-0
mdf4$Waves_attended <- ifelse(mdf4$W1_Present == 1, mdf4$Waves_attended + 1, mdf4$Waves_attended)
mdf4$Waves_attended <- ifelse(mdf4$W2_Present == 1 & mdf4$W1_Present == 1, mdf4$Waves_attended + 1, mdf4$Waves_attended)
mdf4$Waves_attended <- ifelse(mdf4$W3_Type == 0 & mdf4$W1_Present == 1, mdf4$Waves_attended + 1, mdf4$Waves_attended)
mdf4$Waves_attended <- ifelse(mdf4$W4_Type == 1 & mdf4$W1_Present == 1, mdf4$Waves_attended + 1, mdf4$Waves_attended)
mdf4$Waves_attended <- ifelse(mdf4$W5_Type == 1 & mdf4$W1_Present == 1, mdf4$Waves_attended + 1, mdf4$Waves_attended)
mdf4$Waves_attended <- ifelse(mdf4$W6_Type == 1 & mdf4$W1_Present == 1, mdf4$Waves_attended + 1, mdf4$Waves_attended)
table(mdf4$Waves_attended)
```

We used the ifelse function to add 1 to the waves_attended variable if a given respondent was present for a given wave regardless if they had completed all of the previous waves or not. Similar to the "Present_XXX" variable created above we used the wave type and present variables to identify whether or not they completed the survey at a given wave. As we can see the total number of people who didn't attended any waves (Waves_attended = 0) is 3339 - this represents all of the Top-ups across all waves. Below is a bar chart of the above data minus the Top-ups

```{r}
wave_table_total <- table(mdf4$Waves_attended)

# Remove the first count
wave_table_total  <- wave_table_total[-1]

# Plot the bar chart for the frequencies without the first bar
barplot(wave_table_total,
        xlab = "Total number of Waves Attended",
        ylab = "Frequency",
        main = "Total number of waves attended by each responsdant asumming they attened wave 1 
        and was not a top-up",
        ylim = c(0,700)
)
```

The above graph shows how man how many waves each of the respondents attended. It might also be useful to plot this on a line graph to show cumulatively how many attended number of waves. Below is this graph:

```{r}
### Putting previous variable into a matrix

Waves_attended_Total <- matrix(c(2025,1757, 1482, 1205, 972, 582), ncol=1, byrow=TRUE)
rownames(Waves_attended_Total) <- c('1 Wave','2 Waves','3 Waves ','4 Waves','5 Waves','6 Waves')
colnames(Waves_attended_Total) <- c('Present')
Waves_attended_Totaldf<-as.data.frame(Waves_attended_Total)
Waves_attended_Totaldf$Waves <- rownames(Waves_attended_Totaldf)

Waves_attended_Totaldf$Percentage <- (Waves_attended_Totaldf$Present / Waves_attended_Totaldf$Present[1]) * 100
ggplot(Waves_attended_Totaldf, aes(x = Waves, y = Percentage, group = 1)) +
  geom_line(color = "blue") +
  geom_point(color = "blue", size = 3) +
  labs(title = "Total Number of Waves completed", x = "Waves", y = "Percentage") +
  theme_minimal() +
  ylim(c(0,100))
```

This graph shoes how many attended at least each level of waves (I.e 100% completed one wave and around 30% completed all 6 waves) Now that we have created some descriptive statistics we can now go on to explore the impact of depression severity on the number of waves completed. First we need to create a matrix of our results. We can do this by running a table of total number of waves attended and depression severity. Then we can subtract each of these results from wave 1 totals in order to make our matrix:

```{r}
table(mdf4$Waves_attended,mdf4$W1_Dep_Severity)

wave_data1 <- data.frame(
  Severity = c("None minimal (0-4)", "Mild (5-9)", "Moderate (10-14)", "Moderately Severe (15-19)", "Severe (20-27)"),
  At_Least_One_Wave = c(1199, 378, 227, 154, 67),
  At_Least_Two_Waves = c(1083, 313, 185, 131, 45),
  At_Least_Three_Waves = c(952, 260, 137, 99, 34),
  At_Least_Four_Waves = c(797, 204, 104, 76, 24),
  At_Least_Five_Waves = c(660, 162, 78, 54, 18),
  All_Six_Waves =       c(414, 91, 41, 28, 8)
)
```

We can then plot this. As with the other results graph above we used the ggplot2 and the tidyr package. We also again had to use the pivot_longer() command which takes our original wide-format data frame wave_data and converts it into a long-format data frame called wave_data_long, where the wave numbers are stacked in a single column named Wave_Number, and the corresponding frequencies are stacked in another column named Frequency. This transformation allows us to then plot this new data frame.:

```{r}
custom_colors <- c("None minimal (0-4)" = "darkgreen", "Mild (5-9)"= "lightgreen","Moderate (10-14)" = "orange",
                   "Moderately Severe (15-19)" = "red", "Severe (20-27)" = "darkred")
legend_order <- c("None minimal (0-4)", "Mild (5-9)", "Moderate (10-14)", "Moderately Severe (15-19)", "Severe (20-27)")


wave_data1_long <- wave_data1 %>%
  pivot_longer(cols = -Severity, names_to = "Waves", values_to = "Counts") %>%
  mutate(Waves = factor(Waves, levels = c("At_Least_One_Wave", "At_Least_Two_Waves", "At_Least_Three_Waves", "At_Least_Four_Waves", "At_Least_Five_Waves", "All_Six_Waves")))

# Plotting
ggplot(wave_data1_long, aes(x = Waves, y = Counts, group = Severity, color = Severity)) +
  geom_line() +
  labs(title = "Depression Severity Counts Across Waves Completed",
       x = "Waves",
       y = "Count") +
  scale_color_manual(values = custom_colors, breaks = legend_order) +  # You can change the palette if needed
  theme_minimal()
```

We can also show this as a percentage of Wave 1:

```{r}
wave_data1_long <- wave_data1_long %>%
  group_by(Severity) %>%
  mutate(Percentage = Counts / Counts[Waves == "At_Least_One_Wave"] * 100)

# Plotting the line graph with percentages relative to Wave 1 on the y-axis
ggplot(wave_data1_long, aes(x = Waves, y = Percentage, color = Severity, group = Severity)) +
  geom_line() +
  scale_color_manual(values = custom_colors, breaks = legend_order) +  # Assigning custom colors and order
  labs(title = "Percentage of waves completed per person",
       x = "Number of waves completed", y = "Percentage") +
  theme_minimal()

```

We can then run a regression again:

```{r}
### Regression Tests

# Reshape the data to long format

data_long1 <- melt(wave_data1, id.vars = "Severity", variable.name = "Wave", value.name = "Counts")

# Convert Severity to numeric
severity_mapping <- c('None minimal (0-4)' = 1, 'Mild (5-9)' = 2, 'Moderate (10-14)' = 3, 'Moderately Severe (15-19)' = 4, 'Severe (20-27)' = 5)
data_long1$Severity_Num <- as.numeric(factor(data_long1$Severity, levels = names(severity_mapping)))



# Perform OLS regression
model1 <- lm(Counts ~ Wave * Severity_Num, data = data_long1)
summary(model1)
```

while there are differences in how waves are represented between the two models, the significance of predictors and the overall model fit remain similar. The choice between the two representations may depend on the specific research question and the interpretation of the waves.